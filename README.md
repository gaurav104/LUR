# Learning to Unlearn while Retaining (LUR)
**Learning to Unlearn while Retaining: Combating Gradient Conflicts in Machine Unlearning â€” ICCV 2025**

[![Conference](https://img.shields.io/badge/ICCV-2025-1a73e8.svg)](#)
[![Status](https://img.shields.io/badge/status-code%20cleanup%20in%20progress-yellow.svg)](#)
[![License](https://img.shields.io/badge/license-TBD-grey.svg)](#)

> **TL;DR**: LUR is a machine unlearning framework that reduces gradient conflicts between *forget* and *retain* objectives, improving both targeted forgetting and retained utility.

---

## ğŸš§ Repository Status

Weâ€™re performing a thorough code cleanup of the code:
- Consolidating training/eval scripts and configs  
- Verifying reproducibility and seeds  
- Scrubbing internal paths and large artifacts  
- Writing minimal docs and examples

Updates will roll out directly to this repo as theyâ€™re finalized. If youâ€™re interested, please keep a **watch** on the repository.

---

## ğŸ—ï¸ News

- âœ… **Accepted to ICCV 2025**  
- ğŸ”§ Codebase cleanup and documentation in progress

---

## ğŸ”– Citation

If you find this work useful and relevant, please consider to cite it.

```bibtex
@InProceedings{Patel_2025_ICCV,
    author    = {Patel, Gaurav and Qiu, Qiang},
    title     = {Learning to Unlearn while Retaining: Combating Gradient Conflicts in Machine Unlearning},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2025},
    pages     = {4211-4221}
}
