# Learning to Unlearn while Retaining (LUR)
**Learning to Unlearn while Retaining: Combating Gradient Conflicts in Machine Unlearning — ICCV 2025**

[![Conference](https://img.shields.io/badge/ICCV-2025-1a73e8.svg)](#)
[![Status](https://img.shields.io/badge/status-code%20cleanup%20in%20progress-yellow.svg)](#)
[![License](https://img.shields.io/badge/license-TBD-grey.svg)](#)

> **TL;DR**: LUR is a machine unlearning framework that reduces gradient conflicts between *forget* and *retain* objectives, improving both targeted forgetting and retained utility.

---

## 🚧 Repository Status

We’re performing a thorough code cleanup of the code:
- Consolidating training/eval scripts and configs  
- Verifying reproducibility and seeds  
- Scrubbing internal paths and large artifacts  
- Writing minimal docs and examples

Updates will roll out directly to this repo as they’re finalized. If you’re interested, please keep a **watch** on the repository.

---

## 🗞️ News

- ✅ **Accepted to ICCV 2025**  
- 🔧 Codebase cleanup and documentation in progress

---

## 🔖 Citation

If you find this work useful and relevant, please consider to cite it.

```bibtex
@InProceedings{Patel_2025_ICCV,
    author    = {Patel, Gaurav and Qiu, Qiang},
    title     = {Learning to Unlearn while Retaining: Combating Gradient Conflicts in Machine Unlearning},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2025},
    pages     = {4211-4221}
}
